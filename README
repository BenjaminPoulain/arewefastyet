The latest AWFY is five components:
 (1) MySQL database that stores statistics.
 (2) Hidden PHP script on the webserver, where stats get sent.
 (3) Python driver that runs on each benchmark computer, and submits stats.
 (4) Python aggregator that builds JSON data from the DB.
 (5) Static HTML as the frontpage, that queries JSON via XHR.

NOTE: (2), (3), and (5) must be on the same webserver, otherwise timestamps
might not be computed correctly.

######### SET UP ##########
Setting up (1):
  Run database/schema.sql

Setting up (2):
  Drop website/UPDATE.PHP and website/internals.php somewhere, and
  rename UPDATE.PHP to something secret.

Setting up (3):
  I set it up like:

   git clone http://github.com/dvander/arewefastyet awfy
   cd awfy
   mkdir repos
   cd repos

   # Get V8
   svn checkout http://v8.googlecode.com/svn/branches/bleeding_edge/ v8

   # Get Mozilla
   hg clone http://hg.mozilla.org/integration/mozilla-inbound

   # Get WebKit - Mac/Linux only
   svn checkout https://svn.webkit.org/repository/webkit/trunk WebKit

   cd ../driver
   cp awfy.config.sample awfy.config

  (a) Add a database entry for the machine configuration.
  (b) Edit awfy.config to match the build architecture you want, and machine
      database entry.
  (c) Run dostuff.py periodically - Mozilla uses "run.sh" which will run
      continuously, since a cronjob could run overlapping jobs.

   # Note, interrupting dostuff.py can cause problems with subversion, for
   # example, the WebKit repository may become stuck and need an svn cleanup
   # or an rm -rf and clean checkout. For sanity, run.sh will pause its next
   # run if it sees a /tmp/awfy lock in place, and this can be used to wait.

   # Note It is not safe to share multiple AWFY instances from the same
   # repository, since C++ object files are generally re-used and may
   # not correctly link depending on build flags.
   

Setting up (4):
  Put awfy-server.config in /etc/, edit it to point at your database and 
  website/data folder. Then put update.py in a cronjob. It will dump files
  where appropriate. AWFY.com does this every 15min.

  update.py generates various JSON files:
   (a) "raw" and "metadata" files cache database queries from run to run,
       so we don't have to make expensive database queries.
   (b) "aggregate" files are used for the front page.
   (c) "condensed" files are used for one level of zooming, so users don't
       have to download the raw data set right away.
   
  The metadata and raw JSON files are updated as needed. The aggregate and
  condensed files are always re-generated from the raw data.

  There is also a monitor.py script provided in the server folder. You can run
  this regularly to send e-mails for benchmarking machines that haven't sent
  results in a certain amount of time (this time is specified in awfy-server.config).
  It will send e-mail through the local SMTP server, using the "contact" field
  for each machine in the database. This field should be a comma-delimited list
  of e-mail addresses (i.e. "egg@yam.com,bob@egg.com").

Setting up (5):
  Nothing special needed. Note that our flot is slightly modified, so it
  might not work to just replace it.

